from elasticsearch import Elasticsearch
from datetime import datetime, timedelta
import random

# Connect to Elasticsearch cluster
es = Elasticsearch(['localhost:9200'])

# Define index settings and mappings
index_settings = {
    'settings': {
        'index': {
            'number_of_shards': 1,
            'number_of_replicas': 0
        }
    },
    'mappings': {
        'properties': {
            'message': {'type': 'text'},
            'timestamp': {'type': 'date'}
        }
    }
}

# Define index name and date range
index_name = 'my_index'
today = datetime.now().date()
yesterday = today - timedelta(days=1)

# Create index with settings and mappings
if not es.indices.exists(index=index_name):
    es.indices.create(index=index_name, body=index_settings)

# Generate and index 100 random logs for today and yesterday
for i in range(100):
    timestamp = datetime.combine(random.choice([today, yesterday]), datetime.min.time())
    log = {'message': f'This is log {i}', 'timestamp': timestamp}
    try:
        es.index(index=index_name, body=log)
    except Exception as e:
        print(f'Error indexing log: {e}')

# Refresh the index to make the documents searchable
es.indices.refresh(index=index_name)



#############################################
bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 3 --topic my-topic


bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 3 --topic my-topic


from kafka.admin import KafkaAdminClient, NewTopic

# set up admin client
admin_client = KafkaAdminClient(
    bootstrap_servers="localhost:9092",
    client_id="admin",
)

# create a new topic
topic_name = "my-topic"
num_partitions = 3
replication_factor = 1
topic = NewTopic(
    name=topic_name,
    num_partitions=num_partitions,
    replication_factor=replication_factor,
)
admin_client.create_topics([topic])
