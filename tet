import requests
import pandas as pd
from datetime import datetime, timedelta

# YARN ResourceManager URL
yarn_url = "http://<yarn-resource-manager-url>:8088/ws/v1/cluster/apps"

# Set time threshold (3 hours)
time_threshold = timedelta(hours=3)

# Function to get long-running jobs
def get_long_running_jobs(yarn_url, time_threshold):
    response = requests.get(yarn_url, params={"state": "RUNNING"})
    
    # Check if response is valid
    if response.status_code != 200:
        print(f"Failed to retrieve data: {response.status_code}")
        return pd.DataFrame()
    
    data = response.json()
    
    # Collect jobs running longer than threshold
    long_running_jobs = []
    for app in data.get("apps", {}).get("app", []):
        start_time = datetime.fromtimestamp(app["startedTime"] / 1000)
        duration = datetime.now() - start_time
        
        if duration > time_threshold:
            app["duration"] = duration  # Add duration to app data
            long_running_jobs.append(app)
    
    # Convert to DataFrame
    df = pd.DataFrame(long_running_jobs)
    return df

# Get long-running jobs and save to CSV
df_long_running = get_long_running_jobs(yarn_url, time_threshold)
if not df_long_running.empty:
    df_long_running.to_csv("long_running_yarn_jobs.csv", index=False)
    print("Long-running jobs saved to long_running_yarn_jobs.csv")
else:
    print("No long-running jobs found.")
